{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9da0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, QuantileTransformer, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "#from category_encoders import TargetEncoder\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el JSON\n",
    "df_91_20 = pd.read_json('df_91_20.json', orient='records', lines=True)\n",
    "df_91_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22fba0",
   "metadata": {},
   "source": [
    "---\n",
    "## Variable Target\n",
    "\n",
    "Para abordar el problema como una tarea de clasificación, se definió como variable objetivo la temperatura media anual de cada estación, representada por la variable 'Temperatura'. A partir de su valor promedio anual, se clasificaron las estaciones meteorológicas en cuatro categorías:\n",
    "\n",
    "Frías: promedio menor a 10 °C\n",
    "\n",
    "Templadas frescas: entre 10 °C y 15 °C\n",
    "\n",
    "Templadas cálidas: entre 15 °C y 20 °C\n",
    "\n",
    "Cálidas: promedio mayor a 20 °C\n",
    "\n",
    "Esta clasificación busca representar de manera más precisa la variabilidad climática del país. A continuación, se agruparon las observaciones por estación y se asignó una etiqueta a cada una según el promedio de temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos por estación y calculamos el promedio de temperatura\n",
    "\n",
    "df_temperatura_estacion = df_91_20.groupby(\"Estación\")[\"Temperatura\"].mean().reset_index()\n",
    "\n",
    "# Creamos la variable target\n",
    "\n",
    "def clasificar_temp(temperatura):\n",
    "    if temperatura < 10:\n",
    "        return \"fría\"\n",
    "    elif temperatura < 15:\n",
    "        return \"templada fresca\"\n",
    "    elif temperatura < 20:\n",
    "        return \"templada cálida\"\n",
    "    else:\n",
    "        return \"cálida\"\n",
    "\n",
    "df_temperatura_estacion[\"CLASE\"] = df_temperatura_estacion[\"Temperatura\"].apply(clasificar_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ea300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_temperatura_estacion[\"CLASE\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5e851",
   "metadata": {},
   "source": [
    "---\n",
    "## Desbalance de clases\n",
    "\n",
    "Se nota un fuerte desbalance de clases siendo la clase \"templada cálida\" fuertemente predominante. Este desbalance puede afectar negativamente la capacidad del modelo para aprender patrones representativos de las clases minoritarias y esto puede llevar a modelos sesgados o con bajo poder predictivo. Graficamos para mayor claridad: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_temperatura_estacion, x=\"CLASE\", palette=\"coolwarm\")\n",
    "plt.title(\"Distribución de clases por estación\")\n",
    "plt.xlabel(\"Clase térmica\")\n",
    "plt.ylabel(\"Cantidad de estaciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaccaf9",
   "metadata": {},
   "source": [
    "Para corregir este sobremuestreo elegimos aplicar sobremuestreo con SMOTE a las clases minoritarias en lugar de un submuestreo de la clase mayoritaria ya que nos permite conservar mayor cantidad de datos y ayuda a evitar el overfitting. \n",
    "\n",
    "Primero imputamos los valores faltantes y transformamos las variables categóricas en los pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "761e1002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASE\n",
      "templada cálida    40\n",
      "fría               40\n",
      "cálida             40\n",
      "templada fresca    40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definimos variables numéricas y categóricas\n",
    "numericas = df_temperatura_estacion.select_dtypes(include='number').drop(columns=[\"Temperatura\"]).columns.tolist()\n",
    "categoricas = df_temperatura_estacion.select_dtypes(include='object').drop(columns=[\"CLASE\"]).columns.tolist()\n",
    "\n",
    "# Pipelines para imputación y encoding\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ColumnTransformer para las variables numéricas y categóricas\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numericas),\n",
    "    (\"cat\", categorical_pipeline, categoricas)\n",
    "])\n",
    "\n",
    "# Dividimos el dataset antes del preprocesamiento para evitar el data leakage\n",
    "X = df_temperatura_estacion.drop(columns=[\"CLASE\"])\n",
    "y = df_temperatura_estacion[\"CLASE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Ajustamos sólo con el set de entrenamiento\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "#Transformamos\n",
    "X_train_prep = preprocessor.transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "# SMOTE sobre el set de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_prep, y_train)\n",
    "\n",
    "print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b742cd9",
   "metadata": {},
   "source": [
    "Luego de aplicar SMOTE sobre el set de entrenamiento vemos que ahora se logró una distribución balanceada de clases (40 estaciones cada una), esto proporciona una buena base para el posterior entrenamiento del modelo. Nótese que en lugar de obtener 50 estaciones por clase, al haber hecho la división de 80/20 antes de SMOTE la clase mayoritaria pasó a tener 40 ítems, eso explica este número para las demás clases.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017da54",
   "metadata": {},
   "source": [
    "--- \n",
    "## Análisis y selección de features\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "add-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
